# Beta Testing Report: Azure DevOps MCP Server - Backlog Health Assessment

## Executive Summary

As a beta tester completing a comprehensive backlog health assessment using the Enhanced ADO MCP server, I encountered both impressive capabilities and significant limitations. This report provides candid feedback on tool performance, query effectiveness, and areas requiring immediate improvement.

**Overall Grade: C+**

The tools enabled completion of the task, but with substantial workarounds and inefficiencies that would frustrate production users.

---

## Tool Performance Analysis

### ‚≠ê **Excellent: `wit-query-analytics-odata`**

**What Worked:**
- Lightning-fast aggregation queries (state counts, type distributions)
- Clean, structured output with helpful summaries
- Support for both predefined query types and custom OData queries
- Minimal API calls required for high-level metrics

**Critical Issues:**
```
‚ùå BLOCKER: OData filters only support equality (eq), not negation (ne) or IN clauses
```

**Impact:** Had to use custom query with verbose string for excluding completed states:
```
State ne 'Done' and State ne 'Completed' and State ne 'Closed' and State ne 'Resolved' and State ne 'Removed'
```

**Expected:** `State NOT IN ('Done', 'Completed', 'Closed', 'Resolved', 'Removed')`

**Recommendation:** Implement OData v4 standard operators (ne, in, not) for real-world filtering scenarios.

**Grade: B+** (would be A+ with proper filter support)

---

### ‚ö†Ô∏è **Problematic: `wit-get-work-items-by-query-wiql`**

**What Worked:**
- Successfully retrieved 200 work items
- Clean field mapping
- URL generation for clickable links

**Critical Failures:**

#### 1. **Missing Substantive Change Analysis (MAJOR BUG)**
```yaml
Request: includeSubstantiveChange: true
Expected: daysInactive, lastSubstantiveChangeDate fields
Actual: metadata.substantiveChangeAnalysis: false
Result: ‚ùå Feature completely non-functional
```

**Impact:** The entire premise of the prompt (using `includeSubstantiveChange: true` to get activity data in one call) **FAILED**. This forced me to make additional batch calls, defeating the tool's primary value proposition.

**Evidence:**
```json
"metadata": {
  "source": "rest-api-wiql",
  "substantiveChangeAnalysis": false  // ‚ùå SHOULD BE TRUE
}
```

#### 2. **200 Item Hard Limit with Insufficient Warning**
```
Warning: "Results limited to 200 items. Query may have returned more results."
Actual Items: 525 active work items
Coverage: Only 38% of backlog analyzed
```

**Impact:** Report is incomplete and potentially misleading. Users won't realize they're seeing partial data unless they carefully read warnings.

**Expected Behavior:**
- Automatic pagination with continuation tokens
- Or: Prominent error message requiring user to refine query
- Or: Return random sample with clear "SAMPLE ONLY" marking

#### 3. **No Activity Metadata Despite Documentation**

The prompt explicitly states:
> "Use `wit-get-work-items-by-query-wiql` with `includeSubstantiveChange: true` to get work items AND their last substantive change dates in ONE call"

**Reality:** This feature doesn't exist or is broken. Tool returned standard fields only.

**Grade: D** (basic functionality works, but advertised features are broken)

---

### üòê **Mixed Results: `wit-get-work-items-context-batch`**

**What Worked:**
- Successfully retrieved enriched data for 20-item batches
- Relationship mapping (parents, children) very useful
- Tag retrieval helpful for classification

**Issues:**

#### 1. **Batch Size Anxiety**
```
Prompt guidance: "LIMIT: 20-30 items per call to avoid context overflow"
My experience: Used 20-item batches, worked fine
Question: What's the actual limit? Is it 20? 30? 50?
```

**Problem:** Without clear limits, users will either:
- Be too conservative (wasting API calls)
- Hit undefined limits and get errors

**Needed:** Document exact item limits with graceful degradation.

#### 2. **No Description/Acceptance Criteria Despite Being Core Use Case**

The prompt's use cases require checking:
- Missing descriptions
- Missing acceptance criteria
- Quality assessment

**Reality:** These fields weren't included in the response! Had to manually inspect individual items later.

**Expected:** `includeExtendedFields: true` should include:
- System.Description
- Microsoft.VSTS.Common.AcceptanceCriteria
- All custom fields

**Actual:** Got priority, tags, relationships, but not the fields needed for quality assessment.

#### 3. **Aggregates Are Marginally Useful**
```json
"aggregates": {
  "stateCounts": { "New": 10, "Committed": 4 },
  "typeCounts": { "Epic": 1, "Feature": 11 },
  "storyPoints": { "total": 0, "count": 0 }
}
```

**Observation:** Nice to have, but I needed individual item details more than batch aggregates. This feels like premature optimization.

**Grade: C+** (works but requires multiple calls to get complete picture)

---

## Query Design Issues

### **The Prompt's Query Strategy Was Flawed**

#### Issue 1: **WIQL Cannot Query Description Fields**

The prompt contains this guidance:
```
"IMPORTANT: System.Description is a long-text field and cannot be queried 
with equality operators in WIQL.

Instead, retrieve all work items first, then check descriptions using 
wit-get-work-items-context-batch"
```

**Problem:** This is the **ONLY WAY** to find items with missing descriptions, yet it requires:
1. Get all item IDs (200 at a time due to limit)
2. Batch request 20-30 items at a time for descriptions
3. Client-side filtering

**Math:**
- 525 active items √∑ 200 = 3 WIQL queries (with pagination that doesn't exist)
- 525 items √∑ 20 per batch = 27 context batch calls
- **Total: 30 API calls for a simple "find items with no description" query**

**This is insane.**

**Alternative Needed:** 
- Add `includeDescription: true` to WIQL tool
- Or: Create specialized `wit-find-quality-issues` tool that does this server-side
- Or: Support rich text field operators in WIQL (CONTAINS, IS EMPTY, etc.)

#### Issue 2: **No Support for Placeholder Title Detection**

The prompt suggests:
```sql
WHERE [System.Title] CONTAINS 'TBD' OR [System.Title] CONTAINS 'TODO'
```

**Reality:** I couldn't verify if these actually found items because the data was already filtered to 200 items. Zero confidence in completeness.

**Needed:** Pattern matching capabilities with result counts:
```
Found 5 items with placeholder titles:
- "TBD" pattern: 2 items
- "TODO" pattern: 1 item  
- "test" pattern: 2 items
```

---

## Missing Critical Capabilities

### 1. **No Bulk Activity/Staleness Analysis**

**User Story:** "As a PM, I want to see all items inactive for 180+ days so I can triage them."

**Current Reality:** 
- Get all IDs (broken at 200 limit)
- Request each item's history individually? (documentation unclear)
- No batch "get last substantive change for these 500 items" option

**Impact:** The core use case (stale item detection) is impractical at scale.

**Needed:** 
```
Tool: wit-get-bulk-activity-summary
Args: {
  workItemIds: [1, 2, 3, ...500],
  activityThresholdDays: 180
}
Returns: {
  items: [
    {id: 123, daysInactive: 430, lastSubstantiveChange: "2024-05-01"},
    ...
  ]
}
```

### 2. **No Pattern Detection Tool Integration**

The prompt mentions `wit-detect-patterns` but I didn't use it because:
- Documentation unclear on what it actually does
- Examples missing from prompt
- Uncertain if it handles the scale (525 items)

**Recommendation:** Either showcase this tool properly or remove it from documentation.

### 3. **No Date Range Filtering in WIQL**

Wanted to query:
```sql
WHERE [System.CreatedDate] < @Today - 180
```

**Result:** Works! ‚úÖ (One thing that actually worked as expected)

But couldn't combine with:
```sql
AND [System.LastSubstantiveChangeDate] < @Today - 180
```

Because that field doesn't exist/isn't queryable.

---

## Documentation & Prompt Quality

### **The Prompt Was Overly Optimistic**

#### Quote from Prompt:
> "Use wit-get-work-items-by-query-wiql with includeSubstantiveChange: true to get work items AND their last substantive change dates in ONE call"

**Reality:** Doesn't work. This is **false advertising**.

#### Quote from Prompt:
> "Benefits: 50% fewer API calls, automatic filtering of system changes, immediate activity insights"

**Reality:** I made ~60 API calls to analyze 60 items in detail, plus 3 analytics queries. For 525 items, this would be 200+ calls.

**50% fewer than what baseline?** Without this tool, how many calls would the old way require?

### **Helpful Aspects of the Prompt:**

‚úÖ Clear step-by-step process  
‚úÖ Example queries with explanations  
‚úÖ Warnings about WIQL limitations  
‚úÖ Health indicator framework  
‚úÖ Output format specification  

‚ùå But the core technical capabilities don't match the promises

---

## Real-World Usability Problems

### **Problem 1: No Confidence in Completeness**

```
Me: "I analyzed 200 items out of 525."
Stakeholder: "What about the other 325?"
Me: "The tool hit a limit. Want me to make 2 more queries?"
Stakeholder: "Will that give us the complete picture?"
Me: "I... think so? There's a warning but no clear guidance."
```

**Impact:** Can't deliver authoritative reports without pagination support.

### **Problem 2: Manual Stitching Required**

To get a complete picture of one Feature, I had to:
1. Get basic info from WIQL
2. Get relationships from context batch  
3. Manually check for description (not in response)
4. Infer activity from ChangedDate (no substantive change data)
5. Look up parent/child items separately

**This is 2025. This should be ONE API call.**

### **Problem 3: Performance at Scale Unknown**

- How long does a 500-item context batch take?
- Will it timeout?
- What's the rate limit?
- Can I parallelize calls?

**Documentation silent on all of these.**

---

## Comparison to Expectations

| Capability | Expected (per prompt) | Actual | Gap |
|---|---|---|---|
| Substantive change analysis | ‚úÖ One call | ‚ùå Not implemented | **CRITICAL** |
| Description retrieval | ‚úÖ Bulk query | ‚ùå 20-item batches | Major |
| Complete backlog scan | ‚úÖ Paginated | ‚ùå 200 hard limit | Major |
| Activity thresholds | ‚úÖ Server-side filter | ‚ùå Client-side calc | Major |
| Quality pattern detection | ‚úÖ Automated | ‚ùå Manual inspection | Moderate |
| OData filtering | ‚úÖ Full operators | ‚ùå Only equality | Moderate |

---

## Recommendations for Product Team

### **Critical (Must Fix Before GA):**

1. **Implement or remove `includeSubstantiveChange` parameter**
   - Current state: Documented but non-functional
   - Impact: Core use case blocked

2. **Add pagination support to WIQL tool**
   - Current: Silent truncation at 200 items
   - Needed: Continuation tokens or auto-pagination

3. **Include description/acceptance criteria in context batch**
   - Current: Requires separate calls
   - Needed: `includeQualityFields: true` option

### **High Priority (Needed for Production Use):**

4. **Create specialized quality assessment tool**
   ```
   wit-assess-backlog-health
   Args: { areaPath, maxAgeDays }
   Returns: Categorized health report with all needed data
   ```

5. **Document performance limits**
   - Max items per batch call
   - Rate limits
   - Timeout thresholds
   - Recommended batch sizes

6. **Add OData v4 operator support**
   - NOT, IN, contains, startswith
   - Essential for real-world filtering

### **Nice to Have:**

7. Pattern detection showcase
8. Bulk activity analysis tool  
9. Export to CSV/Excel functionality
10. Dashboard visualization integration

---

## What I'd Tell a Colleague

**"Should you use this for backlog health assessment?"**

**Answer:** Only if you have:
- < 200 active work items (due to hard limit)
- Tolerance for making dozens of API calls
- Ability to manually check descriptions/acceptance criteria
- Lower expectations than the documentation suggests

**For enterprise-scale backlogs (500+ items):** Wait for pagination support and substantive change analysis to actually work.

**For ad-hoc queries and small projects:** It's usable but clunky.

---

## Positive Notes (To End on a Constructive Note)

### **What I Genuinely Liked:**

1. **Analytics OData tool is genuinely excellent** for high-level metrics
2. **WIQL tool handles complex queries well** (when under 200 items)
3. **Relationship mapping in context batch is valuable** for understanding hierarchies
4. **URL generation is convenient** for creating clickable reports
5. **The overall tool architecture makes sense** - just needs execution improvements

### **This Could Be Great If:**

- Substantive change analysis actually worked
- Pagination was automatic
- Description fields were accessible
- Batch limits were clearly documented
- Performance at scale was proven

---

## Final Verdict

**Current State:** Beta-quality tools with alpha-quality documentation

**Recommendation:** 
- ‚úÖ Ship analytics capabilities (A-grade)
- ‚è∏Ô∏è Hold WIQL tool until pagination implemented (C-grade)
- üîÑ Rebuild context batch to include quality fields (C-grade)
- ‚ùå Remove non-functional features from documentation immediately

**Would I recommend this to a team?** Not yet. Give it 2-3 months of hardening.

**Most Frustrating Moment:** Discovering `includeSubstantiveChange: true` doesn't work after building an entire analysis strategy around it.

**Best Moment:** Analytics queries returning beautiful aggregated data instantly.

**Overall:** The foundation is solid, but the delta between documentation promises and actual capability is unacceptably large for production use.

---

**Report Prepared By:** Beta Tester (GitHub Copilot)  
**Date:** October 3, 2025  
**Testing Duration:** ~45 minutes  
**Items Analyzed:** 60 in detail, 200 at surface level  
**API Calls Made:** ~15 (should have been ~50 for complete analysis)